---
title: "병렬 프로그래밍이란?"
excerpt: "병렬 프로그래밍에 대한 정리"
# toc: true
# toc_sticky: true
categories: [Parallel programming]
tags: [Parallel programming, OpenMP]
use_math: true
---

> 📢 학교 수업 **병렬프로그래밍기초** 수업에 대한 정리이므로 TMI들이 있을 수 있습니다.

## 병렬 프로그래밍이 왜 필요한가?

- CPU의 속도가 매우 빨라짐(1년에 0.5배, 반도체의 발전과 함께 발전했기 때문에 성장세는 더뎌짐)
- 파워가 너무 높아져서 성능 향상이 더뎌짐
- 주파수를 높여서 성능을 올리는 방법은 한계점에 도달
- 이는 프로세서 디자인에 큰 영향을 끼침
- 하나의 칩 안에 여러개의 CPU 코어를 넣는 CMP(Chip Multiple Processors) 방식으로 발전

### 프로세서를 많이 가지고 있으면 프로그래머에게 도움이 될까?

프로그래머가 칩 안에 많은 코어가 있다는 것을 인식하지 않으면 멀티 코어는 아무 의미가 없다. 멀티 코어 시스템을 어떻게 사용하는 지를 알아야 한다.

일반적인 Serial programming은 멀티 코어 시스템과 전혀 상관없다. 즉 멀티 코어 중 하나의 코어에 할당되어 해당 코어에서만 돌아간다.

Serial programming은 멀티 코어 시스템에서 어떠한 이득도 없다.

성능이 좋아질 수록 원하는 요구사항이 높아지고 있다. 예전에는 꿈도 꾸기 힘들었던 문제들도 시도해보고 있다. 계산 속도와 병렬 프로그래밍으로 더 복잡한 문제에 대해서 해결할 수 있다. 향상된 성능으로 기후 예측, 게놈 프로젝트, 제약, 에너지, 등 다양한 분야와 함께 협력해서 사용한다.

![]({{ site.url }}/assets/images/72 (3).png ){: .align-center }

퍼포먼스의 발전은 트랜지스터의 집적도의 발전과 함께 이루어졌다. 반도체 기술이 발전하여 컴퓨터의 성능이 발전한 것이다.

따라서 근본적으로 반도체에서 야기되는 문제들이 컴퓨터 성능에도 영향을 끼친다.

![]({{ site.url }}/assets/images/72 (4).png ){: .align-center }

1. 반도체의 집적도를 높이기 위해 반도체의 크기를 줄임 → 빠른 프로세서를 얻어 성능을 향상
2. 빨라질수록 파워가 증가, 주파수에 비례하여 파워 증가
3. 파워가 높아짐으로 점점 프로세서의 발열 문제가 심각
4. 발열이 심할수록 프로세서의 상태가 불안정해짐

트랜지스터로 인한 성능향상이 한계가 있기 때문에 멀티 코어 시스템으로 경로를 틀었다. 현재는 예전에 비해 칩 하나 당 최고 스피드는 낮지만 여러 개의 멀티코어를 넣어 성능을 향상시킨다.

![]({{ site.url }}/assets/images/72 (5).png ){: .align-center }

멀티 코어를 가면서 하나 코어의 스피드는 떨어트린 이유는 안정적인 프로세서를 지원하기 위해서이다.

## 병렬 프로그래밍 예시

![]({{ site.url }}/assets/images/72 (6).png ){: .align-center }

일반적으로 Serial programming을 Parallel programming으로 만드려면 코드를 다시 만들어야 한다. 제한적으로 변환해 줄 수는 있지만 많은 부분은 새롭게 재작성 해야한다.

![]({{ site.url }}/assets/images/72 (7).png ){: .align-center }

병렬화 알고리즘을 왜 만들어야 하는지 생각해보자. 위 식은 루프를 돌면서 다음 값을 계산하여 합을 구하는 간단한 알고리즘이다.

![]({{ site.url }}/assets/images/72 (8).png ){: .align-center }

$p$개의 프로세스/코어를 가지고 있으며 일반적으로 $p$는 $n$보다 아주 작다. 일반적으로 병렬 프로세스라 하면 각각의 코어가 부분 합을 구하면 된다.

`my_sum` = 각각의 코어가 계산하는 합 (_각각의 부분 합 )_

![]({{ site.url }}/assets/images/72 (9).png ){: .align-center }

각 코어는 각각의 계산 결과를 `my_sum`에 축적한다. 코어가 8개라면 8개의 구간으로 나누어져 합이 계산될 것이다.

![]({{ site.url }}/assets/images/72 (10).png ){: .align-center }

각 코어는 독립적인 `my_sum`을 가지고 있을 것이고 우리의 목표는 전체 합(_부분합들의 합_ )이므로 마스터가 아닌 코어들은 마스터 코어에게 부분합 결과 값을 보내주어야 한다.

![]({{ site.url }}/assets/images/72 (11).png ){: .align-center }

최종적으로 합치면 전체 합을 구할 수 있다. 이 방법이 가장 쉽게 생각할 수 있는 병렬 프로그래밍이지만 더 좋은 방법이 있다.

![]({{ site.url }}/assets/images/72 (12).png ){: .align-center }

마스터 코어가 모든 일을 다 할 필요는 없다.

![]({{ site.url }}/assets/images/72 (13).png ){: .align-center }

트리 방식으로 수행하면 $O(log_2N)$

병렬 프로그래밍의 성능은 알고리즘과 결과값을 주고 받는 통신도 잘 고려해야 한다.

![]({{ site.url }}/assets/images/72 (14).png ){: .align-center }

![]({{ site.url }}/assets/images/72 (15).png ){: .align-center }

### Work을 나누어 주는 방법

가장 쉽게 접근할 수 있는 방법이다. 예를 들어 각각의 조교들한테 시험지를 100장씩 나누어 준다. 3명의 조교들이 동시에 끝난다면 이상적이겠지만 그렇지 않을 경우 비효율적으로 작동한다. 또한 조교들이 모든 문제를 다 잘 알아야 한다.

![]({{ site.url }}/assets/images/72 (16).png ){: .align-center }

즉, 담당하고 있는 작업을 다 나눈다. 이 경우 작업 별로 의존성이 없어야 한다. 작업의 양에 따라 불균형이 일어날 수 있다.

![]({{ site.url }}/assets/images/72 (17).png ){: .align-center }

![]({{ site.url }}/assets/images/72 (18).png ){: .align-center }

위 경우 마스터 코어가 결과를 다 모아오는 역할을 한다.

### **Data Parallelism**

- 동일한 데이터의 다른 하위 집합에서 동일한 작업을 수행한다.
- 동기식 연산(Synchronous computation)을 수행한다.
- 모든 데이터 세트에서 동작하는 실행 스레드가 하나뿐이기 때문에 속도 향상은 더욱 빠르다.
- 병렬화의 양은 입력 크기에 비례한다.
- 멀티프로세서 시스템의 최적 부하 균형을 위해 설계되었다.

### **Task Paralism**

- 동일하거나 다른 데이터에 대해 다른 작업을 수행한다.
- 비동기 연산(Asynchronous computation)을 수행한다.
- 각 프로세서가 동일하거나 다른 데이터 집합에서 서로 다른 스레드 또는 프로세스를 실행하므로 속도 향상은 적다.
- 병행화의 양은 독립적인 업무의 수에 비례한다.
- 여기서 로드 밸런싱은 하드웨어의 가용성과 정적 및 동적 스케줄링과 같은 스케줄링 알고리즘에 따라 달라진다.

![]({{ site.url }}/assets/images/72 (19).png ){: .align-center }

병렬 프로그래밍에는 세 가지 오버헤드가 있다.

1. Communication

   태스크를 나누고, 데이터를 나누기 때문에 필연적으로 통신(오버헤드)이 생김

2. Load balancing

   일을 코어별로 동등하게 나누어야 하며 한 쪽에만 많은 일을 주면 비효율적임

   ex) 트리형태로 만들어 로드 밸런싱을 유지

3. Synchronization

   크리티컬 섹션에 대해 접근할 때 비동기 문제가 일어날 수 있음

좋은 성능을 얻기 위해서는 위 세가지 요소를 고려주어야 한다.

![]({{ site.url }}/assets/images/72 (20).png ){: .align-center }

## Parallel system

1. 공유 메모리 기반

   모든 프로세서가 메모리 공간을 공유하고 있다. 하나의 주소 공간을 가지고 모든 프로세서가 사용하고 있다. 즉, 특정한 메모리 공간을 모든 프로세서들이 같이 보고 있으며 공유되는 주소를 업데이트하는 것으로 **통신**을 할 수 있다.

2. 분산 메모리 기반

   모든 코어가 각각의 고유한 메모리를 가지고 있다. 공유 변수를 가지고 있지 않기 때문에 코어 $A$에서 코어 $B$로 통신을 하려면 다른 방법이 필요하다. **send-receive communication**이 일어나야 한다.

시스템이 바뀌면 프로그래밍을 하는 방식도 달라진다.

![]({{ site.url }}/assets/images/72 (21).png ){: .align-center }

$(a)$ = **shared memory**

$(b)$ = **distributed memory**

![]({{ site.url }}/assets/images/72 (22).png ){: .align-center }

1. Concurrent computing

   프로그램이 어느 순간에 여러개의 프로그래밍이 돌아가는 것처럼 보임 (라운드 로빈)

   하지만 실질적으로 병렬 프로그래밍은 아님

2. Parallel computing

   하나의 프로그램이 동일한 여러 개의 태스크로 나누어져 있어 여러 개의 프로세서가 실행

3. Distributed computing

   하나의 프로그램이 서로 다른 작업 별로 나누어서 일을 하는 것

![]({{ site.url }}/assets/images/72 (23).png ){: .align-center }

병렬 컴퓨팅은 멀티 코어로 시작된다. 병렬 알고리즘 기반 병렬 프로그래밍으로 작성해야 하기 때문에 어떻게 써야하는지 알아야 하고 일반적으로 병렬 프로그래밍은 굉장히 복잡하다.

![]({{ site.url }}/assets/images/72 (24).png ){: .align-center }

OpenMP는 병렬프로그래밍을 위한 고수준의 표준 시스템이며 현재 Parallel studio는 OpenMP 4.5까지 지원한다.

![]({{ site.url }}/assets/images/72 (25).png ){: .align-center }

![]({{ site.url }}/assets/images/72 (26).png ){: .align-center }

$(a)$ = **shared memory**

여러 개의 프로세서가 메모리를 공유함. 즉 메모리에 접근 속도가 다 같음.

$(b)$ = **distributed memory**

메모리에 접근 속도가 각각 다름. 다른 프로세서의 메모리에 접근하려면 IPC로 해야하기 때문

## OpenMP

OpenMP는 공유 메모리 환경에서의 병렬 프로그래밍을 위한 스펙이다. Fortran, C, C++에서 공유 메모리의 병렬화를 지정하는데 사용할 수 있는 `pragma`, 실행 루틴, 환경변수들을 제공한다.

### OpenMP의 기본적인 아이디어

필요한 때에 병렬 프로그래밍을 할 수 있게 하자!

![]({{ site.url }}/assets/images/72 (27).png ){: .align-center }

**Directives**

컴파일러의 옵션 중 하나, 병렬 구간을 설정하며 어떻게 병렬화할 것인지 메소드를 정의한다.

**OpenMP Library**

다양한 환경 변수들을 세팅할 수 있다.

![]({{ site.url }}/assets/images/72 (28).png ){: .align-center }

## Fork-join model

쓰레드의 fork, join 방식의 기본적인 모델

![]({{ site.url }}/assets/images/72 (29).png ){: .align-center }

![]({{ site.url }}/assets/images/72 (30).png ){: .align-center }

$B()$가 워크로드가 많을 경우 이런 방식은 오래 걸린다. $B()$를 parallel block으로 정의하고 멀티 쓰레딩을 한다면 다음과 같다.

![]({{ site.url }}/assets/images/72 (31).png ){: .align-center }
